#spark  [[Spark]]

* A Spark application must have only 1 active Spark session at any point of time.
# SparkSession Attributes

1. builder

[[Spark Commands]]
```
spark = SparkSession.builder.getOrCreate()
```


2. read
3. readStream
4. catalog
5. conf
6. udf
7. sparkContext
8. version


# Builder Methods
1. appName
2. master
3. config
4. enableNativeSupport
5. getOrCreate
# SparkSession Methods

1. createDataFrame
2. getActiveSession
3. newSession
4. range
5. sql
6. stop
7. table



# SparkContext

* Belongs to low level Spark Core structure.
* represents  the connection to spark cluster.
* it is the gateway to Spark core APIs.
* can be used to create RDD and broadcast variables on the cluster.

on the other hand:
* SparkSession belongs to high level Spark SQL structure.
* It is the gateway to higher level Spark SQL and DataFrame APIs.
* It holds the SparkContext.
