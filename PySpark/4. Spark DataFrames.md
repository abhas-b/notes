#spark [[Spark]]

# Creating DataFrames

* Offered by [[3. SparkSession]]

1. read
	1. Results in a DataFrameReader object
2. sql
	1. Results a DataFrame
3. table
	1. input arg: table name
	2. Basically converts a table into df.

```
df = spark.table("spark_db.table_name")
```
4. range
	1. supports only single column df
```
df = spark.range(5)
```
5. createDataFrame
	1. does list to df conversion



Note: toDF() is a transformation.


# Transformations
* Each record in df is an object oof type Row.
* Scenarios in which Row is required:
	* Manually creating a df
	* Collecting df rows to the driver
	* Work with single column Row in transformations.
		* Mainly used with unstructured data.
* First two scenarios are mainly used in unit testing or development.

* The Row object is mainly used for unit testing.
* 