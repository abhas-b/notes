#ml [[ML Concepts]]

1. [[Sigmoid]]
	1. It takes any real number as input and outputs a value between 0 and 1.
	2. The function is differentiable everywhere, which is important for optimization algorithms in machine learning.
	3. It can represent the probability of an event occurring.
	4. In logistic regression, it maps the output of a linear model to a probability value between 0 and 1.


$$\frac{1}{1 + e^{-x}}$$


2. [[Tanh]]
3. [[ReLU]]
	1. < 0: 0, >0: linear